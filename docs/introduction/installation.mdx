---
title: "Installation & Setup"
description: "Getting started with BeeAI on your system"
---

BeeAI platform supports installation on **macOS**, **Linux**, and **Windows** (via WSL2) through multiple methods.

## Installation Methods

<Tabs>
<Tab title="Homebrew (Recommended)">

### Install via Homebrew

[Homebrew](https://brew.sh/) is the recommended installation method as it automatically handles dependencies and configures background services.

<Steps>
<Step title="Set up Homebrew">

If you don't have Homebrew installed:

```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

<Note>
Follow the post-installation instructions shown in the terminal to add Homebrew to your PATH.
</Note>
</Step>

<Step title="Install BeeAI">

```bash
brew install i-am-bee/beeai/beeai
brew services start beeai
```

The BeeAI server will start automatically as a background service.
</Step>
</Steps>

### Updating BeeAI

```bash
brew upgrade beeai
brew services restart beeai
```

<Note>
Agents are updated automatically when new versions are available.
</Note>

### Uninstalling BeeAI

```bash
brew services stop beeai
brew uninstall beeai
```

</Tab>

<Tab title="PyPI">

### Install via PyPI

<Warning>
This method requires manual setup of dependencies and does not manage the BeeAI server automatically. We recommend using Homebrew instead if possible.
</Warning>

<Steps>
<Step title="Install a Container Runtime">

BeeAI requires a container runtime to function. Choose one of:

- [Rancher Desktop](https://rancherdesktop.io/) (recommended)
- [Docker Desktop](https://www.docker.com/products/docker-desktop/)
- [Podman Desktop](https://podman-desktop.io/)
- Lima (macOS only)

Install and verify the container runtime is working before proceeding.
</Step>

<Step title="Install pipx">

[pipx](https://pipx.pypa.io/) is recommended for installing Python applications:

```bash
# macOS
brew install pipx
pipx ensurepath

# Ubuntu/Debian
sudo apt update
sudo apt install pipx
pipx ensurepath

# Fedora
sudo dnf install pipx
pipx ensurepath
```

<Tip>
If you use [uv](https://docs.astral.sh/uv/), you can use `uv tool install beeai-cli` instead.
</Tip>
</Step>

<Step title="Install BeeAI">

```bash
pipx install beeai-cli
```
</Step>

<Step title="Run the BeeAI Server">

Unlike the Homebrew installation, you'll need to manually start the BeeAI server:

```bash
beeai serve
```

<Note>
Keep this terminal window open while using BeeAI, or set up a system service to run it in the background.
</Note>
</Step>
</Steps>

### Updating BeeAI

```bash
pipx upgrade beeai-cli
```

### Uninstalling BeeAI

```bash
pipx uninstall beeai-cli
```

</Tab>
</Tabs>

## Windows Setup with WSL2

<Accordion title="Detailed Windows (WSL2) Setup Instructions">

Windows users need to set up [WSL2 (Windows Subsystem for Linux)](https://learn.microsoft.com/en-us/windows/wsl/install) before installing BeeAI:

<Steps>
<Step title="Install WSL2">

1. Open PowerShell or Command Prompt as Administrator
2. Run the WSL installation command:

```powershell
wsl --install
```

3. Restart your computer when prompted
4. After restart, a terminal window will open to complete the Ubuntu installation
5. Create a username and password for your Ubuntu installation
</Step>

<Step title="Set Up a Container Runtime">

Choose one of the following options:

**Rancher Desktop (Recommended)**
1. [Download and install Rancher Desktop](https://rancherdesktop.io/)
2. During installation, select "dockerd" as the container runtime
3. Go to Preferences > WSL Integration
4. Enable integration for your Ubuntu distro

**Docker Desktop**
1. [Download and install Docker Desktop](https://www.docker.com/products/docker-desktop/)
2. During installation, check "Use WSL 2 instead of Hyper-V"
3. Go to Settings > Resources > WSL Integration
4. Enable integration for your Ubuntu distro

**Podman Desktop**
1. [Download and install Podman Desktop](https://podman-desktop.io/)
2. Follow the [documentation for socket forwarding to WSL2](https://podman-desktop.io/docs/podman/accessing-podman-from-another-wsl-instance)
</Step>

<Step title="Configure WSL for Ollama (Optional)">

If you want to use [Ollama](https://ollama.com/) for local LLM access:

1. [Download and install the Windows version of Ollama](https://ollama.com/download/windows)
2. Create or edit the WSL configuration file:
   
   ```powershell
   notepad $HOME\.wslconfig
   ```

3. Add the following lines:

   ```ini
   [wsl2]
   networkingMode=mirrored
   ```

4. Restart WSL by running in PowerShell:

   ```powershell
   wsl --shutdown
   ```

5. This will allow your WSL2 environment to access the Windows Ollama service
</Step>

<Step title="Use BeeAI in WSL">

1. Open your WSL2 terminal (you can type "Ubuntu" in the Start menu)
2. Follow the standard installation instructions for either Homebrew or PyPI
3. All BeeAI commands should be run from the WSL2 terminal, not from Windows directly
</Step>
</Steps>

</Accordion>

## LLM Provider Configuration

After installation, configure your preferred LLM provider.

<Tabs>
<Tab title="Interactive Setup (Recommended)">

Run the interactive setup wizard:

```bash
beeai env setup
```

The wizard will:
1. Help you select from popular LLM providers
2. Guide you through API key configuration
3. Test the connection to ensure everything works
4. Save the configuration for future use

<Tip>
You can re-run this command anytime to change your LLM provider.
</Tip>

</Tab>

<Tab title="Manual Configuration">

If you prefer to configure your LLM provider manually, use the following examples:

<AccordionGroup>
<Accordion title="OpenAI API">

```bash
beeai env add LLM_API_BASE=https://api.openai.com/v1
beeai env add LLM_API_KEY=sk-your-api-key-here
beeai env add LLM_MODEL=gpt-4o
```

</Accordion>

<Accordion title="Anthropic Claude API">

```bash
beeai env add LLM_API_BASE=https://api.anthropic.com/v1/
beeai env add LLM_API_KEY=your-api-key-here
beeai env add LLM_MODEL=claude-3-7-sonnet-20250219
```

</Accordion>

<Accordion title="Groq API">

```bash
beeai env add LLM_API_BASE=https://api.groq.com/openai/v1
beeai env add LLM_API_KEY=gsk-your-api-key-here
beeai env add LLM_MODEL=deepseek-r1-distill-llama-70b
```

</Accordion>

<Accordion title="Ollama (Local LLM)">

```bash
beeai env add LLM_API_BASE=http://localhost:11434/v1
beeai env add LLM_API_KEY=ollama
beeai env add LLM_MODEL=llama3.3
```

<Note>
Ensure Ollama is running and the selected model is downloaded before using BeeAI.
</Note>

</Accordion>

<Accordion title="OpenRouter">

```bash
beeai env add LLM_API_BASE=https://openrouter.ai/api/v1
beeai env add LLM_API_KEY=sk-or-v1-your-api-key-here
beeai env add LLM_MODEL=google/gemini-2.0-pro-exp-02-05:free
```

<Tip>
OpenRouter allows access to various models with a single API key. [See their documentation](https://openrouter.ai/docs) for available models.
</Tip>

</Accordion>

<Accordion title="Custom Provider">

For custom or self-hosted OpenAI-compatible API endpoints:

```bash
beeai env add LLM_API_BASE=https://your-custom-endpoint.com/v1
beeai env add LLM_API_KEY=your-api-key
beeai env add LLM_MODEL=your-model-name
```

</Accordion>
</AccordionGroup>

</Tab>
</Tabs>

## Verify Your Installation

After installation and LLM configuration, verify that everything is working properly:

```bash
beeai list
```

This command should display a list of available agents.

<Note>
Agents should show a status of `ready` when fully installed. If you see `installing` status, wait for the operation to complete.
</Note>
