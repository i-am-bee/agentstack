---
title: "Installation"
description: "Instructions for installing BeeAI"
icon: "wrench"
---

The BeeAI platform supports installation on **macOS**, **Linux**, and **Windows** (via WSL2) using multiple methods.

The preferred installation method is via [Homebrew](https://brew.sh/). Homebrew simplifies dependency management and automatically handles background services.

It's also possible to install BeeAI directly from PyPI, with some required manual steps.

<Accordion title="Windows (WSL2) setup instructions">

Windows is supported through the [Windows Subsystem for Linux version 2 (WSL2)](https://learn.microsoft.com/en-us/windows/wsl/install). The following steps need to be taken in order to prepare your system to install BeeAI.

<Steps>
<Step title="Set up WSL2">

Right-click the Start menu and open an Administrator terminal. Run:

```sh
wsl --install
```

...and follow the on-screen instructions until fully installed (which may require a reboot).

</Step>
<Step title="Set up a container runtime">

- [Rancher Desktop](https://rancherdesktop.io/) (recommended): After installation, go to `Preferences > WSL`, enable integration for your default WSL distro (usually `Ubuntu`) and 
- [Docker Desktop](https://docs.docker.com/desktop/setup/install/windows-install/): During installation, select `WSL2` as the backend. Be aware of the Docker Desktop licence limitations for personal use.
- [Podman Desktop](https://podman-desktop.io/) (untested): After installation and first-time setup, follow the [documentation for socket forwarding to WSL2](https://podman-desktop.io/docs/podman/accessing-podman-from-another-wsl-instance).

</Step>
<Step title="Optional: Set up Ollama">

If you want to use [Ollama](https://ollama.com/), we recommend you [install the Windows version](https://ollama.com/download/windows). The Linux version may not work properly.

Open the file `C:/Users/<your name>/.wslconfig` (create it if it's not there) and add the following contents:

```ini
[wsl2]
networkingMode=mirrored
```

Finally, **restart your computer**.

This will allow you to access the Windows version of Ollama inside WSL2.

</Step>
<Step title="Open WSL2">

Right-click the Start menu and open a terminal. Run `wsl` to switch to the WSL2 command shell. Follow the installation instructions below, but use the `wsl` shell to run all of the commands.

</Step>
</Steps>
</Accordion>

<Tabs>
<Tab title="Homebrew (recommended)">

## Install BeeAI with Homebrew

This method uses [Homebrew](https://brew.sh/). Homebrew can be used on all supported platforms: **macOS**, **Linux** and **Windows (WSL2)**.

### Install

<Steps>
<Step title="Set-up Homebrew">

If you are not already a user, first install Homebrew by running this command:

```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

<Warning>After the installation is complete, the output will contain instructions to update your shell environment. Do not forget to follow these instructions.</Warning>
</Step>
<Step title="Install BeeAI">

```sh
brew install i-am-bee/beeai/beeai
beeai platform start
```

</Step>
</Steps>

### Update

<Note>Agents are updated automatically.</Note>

```sh
brew upgrade beeai
beeai platform start
```

### Uninstall

```sh
beeai platform delete
brew uninstall beeai
```

</Tab>
<Tab title="PyPI">

## Install BeeAI with PyPI

This method installs BeeAI using Pythonâ€™s package manager, and is usable on all supported platforms: **macOS**, **Linux** and **Windows (WSL2)**.

### Install

<Steps>
<Step title="Install a container runtime">

Manually installed BeeAI needs you to provide a container runtime. If you already use one (Docker, Rancher, Colima, etc.), it will be detected and used for running agents. If you use a non-Docker container runtime like Podman, make sure to install the Docker compatibility layer so that the `docker` CLI is available.

If you are not sure, the simplest way is to install [Rancher Desktop](https://rancherdesktop.io/) for your platform.

</Step>
<Step title="Install pipx">

If you are not already a user, [install pipx according to the official instructions](https://pipx.pypa.io/stable/installation/#installing-pipx).

<Tip>

If you use [uv](https://docs.astral.sh/uv/), you may use `uv tool` as an alternative to `pipx`, e.g. `uv tool install beeai-cli`.

</Tip>

</Step>
<Step title="Install BeeAI">

```sh
pipx install beeai-cli
```

</Step>
<Step title="Start the BeeAI platform">

```sh
beeai platform start
```

</Step>
</Steps>

### Update

```sh
pipx upgrade beeai
```

### Uninstall

```sh
pipx uninstall beeai
```

</Tab>
</Tabs>

## Post-installation setup

### LLM provider setup

After installation, configure your preferred LLM provider.

<Tabs>
<Tab title="Interactive setup">

```sh
beeai env setup
```

</Tab>
<Tab title="Manual setup">

To configure manually, follow these examples:

<AccordionGroup>
<Accordion title="OpenAI">

```bash
beeai env add LLM_MODEL=gpt-4o
beeai env add LLM_API_BASE=https://api.openai.com/v1
beeai env add LLM_API_KEY=sk_[...] # <- your API key here
```

</Accordion>
<Accordion title="Anthropic">

```bash
beeai env add LLM_MODEL=claude-3-7-sonnet-20250219
beeai env add LLM_API_BASE=https://api.anthropic.com/v1/
beeai env add LLM_API_KEY=[...] # <- your API key here
```

</Accordion>
<Accordion title="Groq">

```bash
beeai env add LLM_MODEL=deepseek-r1-distill-llama-70b
beeai env add LLM_API_BASE=https://api.groq.com/openai/v1
beeai env add LLM_API_KEY=gsk_[...] # <- your API key here
```

</Accordion>
<Accordion title="Ollama">

```bash
beeai env add LLM_MODEL=llama3.3
beeai env add LLM_API_BASE=http://localhost:11434/v1
beeai env add LLM_API_KEY=ollama
```

</Accordion>
<Accordion title="OpenRouter">

```bash
beeai env add LLM_MODEL=google/gemini-2.0-pro-exp-02-05:free
beeai env add LLM_API_BASE=https://openrouter.ai/api/v1
beeai env add LLM_API_KEY=sk-or-v1-[...] # <- your API key here
```

</Accordion>
</AccordionGroup>


</Tab>
</Tabs>

### Verify installation

To verify the installation, run:

```sh
beeai list
```

Ensure all agents display the `ready` status. Note that initial setup might take a few minutes.

At this point, you may also wish to enable [Agent Traceability](/observability/agents-traceability).
