---
title: "Multi-Turn Conversations"
---

Agents are stateless by default. To maintain conversation history across messages, you need to implement memory storage.

## Basic Memory Implementation

Store conversation data using the `context.context_id` as a key:

```python
from collections import defaultdict

# Store conversations globally
conversations = defaultdict(list)

@server.agent()
async def memory_agent(input: Message, context: RunContext):
    user_message = get_message_text(input)
    context_id = context.context_id
    
    # Retrieve conversation history
    history = conversations[context_id]
    
    # Add current message
    history.append({"role": "user", "content": user_message})
    
    # Generate response
    response = f"Message {len(history)} in this conversation"
    history.append({"role": "assistant", "content": response})
    
    yield response
```

## LLM Integration with History

Pass conversation history to the LLM for context-aware responses:

```python
@server.agent()
async def contextual_agent(
    input: Message, 
    context: RunContext,
    llm: Annotated[LLMServiceExtensionServer, LLMServiceExtensionSpec.single_demand()]
):
    if not llm:
        yield "LLM not configured"
        return
        
    user_message = get_message_text(input)
    context_id = context.context_id
    
    # Get conversation history
    history = conversations[context_id]
    
    # Format for LLM (last 10 messages)
    messages = [{"role": "system", "content": "You are a helpful assistant"}]
    messages.extend(history[-10:])  # Limit context window
    messages.append({"role": "user", "content": user_message})
    
    # Call LLM
    config = llm.data.llm_fulfillments.get("default")
    client = OpenAI(base_url=config.api_base, api_key=config.api_key)
    
    response = await client.chat.completions.create(
        model=config.api_model,
        messages=messages
    )
    
    reply = response.choices[0].message.content
    
    # Store exchange
    conversations[context_id].extend([
        {"role": "user", "content": user_message},
        {"role": "assistant", "content": reply}
    ])
    
    yield reply
```

## Agent Configuration

Set the interaction mode to indicate multi-turn support:

```python
from beeai_sdk.a2a.extensions import AgentDetail

@server.agent(
    detail=AgentDetail(interaction_mode="multi-turn")
)
async def my_agent(input: Message, context: RunContext):
    # Implementation
    pass
```

The `context.context_id` uniquely identifies each conversation session. Store data in global dictionaries keyed by this ID to maintain state across function calls.
