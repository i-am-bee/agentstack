---
title: "Overview"
description: "Deploy the BeeAI Platform for your team"
---

BeeAI Platform can be deployed as a centralized instance for your team, providing a shared environment where developers can publish agents and end users can discover and run them. This guide covers the available deployment options and configurations.

## Why Deploy BeeAI?

A team deployment of BeeAI offers:

- **Centralized Agent Catalog**: Easily browse and manage all your team's agents in one searchable hub.
- **Shared LLM Configuration**: Centrally manage model providers, API keys, and usage settings.
- **Consistent User Experience**: Deliver a unified interface across all agents, improving usability and reducing friction.
- **Resource Management**: Allocate compute resources and monitor usage to control costs.
- **Access Control**: Implement team-based authentication, role-based permissions, and secure access policies.

## Deployment Options

BeeAI supports multiple deployment targets to fit your infrastructure.

### Kubernetes

Deploy BeeAI using standard Kubernetes clusters. Supports Helm-based installation and full customization of resources, secrets, and scaling policies.

### OpenShift

Deploy BeeAI on Red Hat OpenShift with support for integrated security, route management, and platform-specific optimizations.