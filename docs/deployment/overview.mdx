---
title: "Overview"
description: "Deploy the BeeAI Platform for your team"
---

BeeAI Platform can be deployed as a centralized instance for your team, providing a shared environment where developers can publish agents and end users can discover and run them.

## Why Deploy BeeAI?

A team deployment offers:

- **Centralized Agent Catalog**: All team agents in one searchable location
- **Shared LLM Configuration**: Manage API keys and model settings centrally  
- **Resource Management**: Control compute resources and costs
- **Team Collaboration**: Share agents and workflows across the organization

## Deployment Options

<CardGroup cols={2}>
  <Card title="Kubernetes" icon="dharmachakra" href="/deployment/kubernetes">
    Deploy using Helm on any Kubernetes cluster
  </Card>
  
  <Card title="OpenShift" icon="redhat" href="/deployment/openshift">  
    Deploy on Red Hat OpenShift with enhanced security
  </Card>
</CardGroup>

## Requirements

- Kubernetes cluster with admin access
- Helm 3.x installed
- Internet access for LLM providers
- Persistent storage for PostgreSQL

## Quick Start

1. Choose your platform (Kubernetes or OpenShift)
2. Follow the platform-specific deployment guide
3. Configure your LLM provider
4. Add agents to your catalog
5. Share access with your team
