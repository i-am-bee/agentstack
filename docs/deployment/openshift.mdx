---
title: "OpenShift"
description: "Deploy BeeAI on an OpenShift cluster using Helm charts"
---

## Prerequisites

- OpenShift cluster (local or cloud)
- Helm 3.x installed
- oc CLI configured to access your cluster
- BeeAI installed for post-deployment configuration
- Cluster admin privileges (for security context constraints)

## Installation

### Step 1: Create Project

Create a dedicated project for BeeAI:

```bash
oc new-project beeai-platform
```

### Step 2: Configure Security Context Constraints

OpenShift requires specific security context constraints. Create an SCC for BeeAI:

`beeai-scc.yaml`:
```yaml
apiVersion: security.openshift.io/v1
kind: SecurityContextConstraints
metadata:
  name: beeai-scc
allowHostDirVolumePlugin: false
allowHostIPC: false
allowHostNetwork: false
allowHostPID: false
allowHostPorts: false
allowPrivilegedContainer: false
allowedCapabilities: []
defaultAddCapabilities: []
fsGroup:
  type: RunAsAny
readOnlyRootFilesystem: false
requiredDropCapabilities: []
runAsUser:
  type: RunAsAny
seLinuxContext:
  type: MustRunAs
supplementalGroups:
  type: RunAsAny
volumes:
- configMap
- downwardAPI
- emptyDir
- persistentVolumeClaim
- projected
- secret
```

Apply the SCC:

```bash
oc apply -f beeai-scc.yaml
```

### Step 3: Create Service Account and Bind SCC

```bash
# Create service account
oc create serviceaccount beeai-sa

# Bind the SCC to the service account
oc adm policy add-scc-to-user beeai-scc -z beeai-sa
```

### Step 4: Create Configuration File

Create a values file with OpenShift-specific configuration:

`openshift-config.yaml`:
```yaml
# OpenShift-specific settings
serviceAccount:
  create: false  # We created it manually
  name: beeai-sa

# Security context for OpenShift
podSecurityContext:
  runAsNonRoot: true
  seccompProfile:
    type: RuntimeDefault

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: false
  runAsNonRoot: true

# Agent pod security context
agent:
  podSecurityContext:
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: false
    runAsNonRoot: true

# Service configuration (change from default NodePort to ClusterIP for OpenShift)
service:
  type: ClusterIP  # Use ClusterIP since OpenShift Routes will handle external access

# If you want to include agents from the default catalog:
externalRegistries:
  public_github: "https://github.com/i-am-bee/beeai-platform@release-v0.2.0#path=agent-registry.yaml"

# Your custom agents as docker images
providers:
  # e.g.
  # - location: ghcr.io/i-am-bee/beeai-platform-agent-starter/my-agent:latest
  - location: <docker-image-id>

# Generate the encryption key:
#  - using UV (https://docs.astral.sh/uv/getting-started/installation/)
#   $ uv run --with cryptography python3 -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())'
#  - using python3 directly
#   $ python3 -m pip install cryptography
#   $ python3 -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())'
encryptionKey: "encryption-key-from-command"

features:
  uiNavigation: true  # Enable UI navigation (default is false)

# Authentication configuration
auth:
  enabled: true
  admin_password: "my-secret-password"

# Help us improve the platform by sharing anonymized telemetry data
telemetry:
  sharing: true

# PostgreSQL configuration for OpenShift
postgresql:
  enabled: true
  auth:
    enablePostgresUser: true
    username: beeai-user
    password: "password"
    database: beeai
  primary:
    podSecurityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    containerSecurityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: false
      runAsNonRoot: true
```

### Step 5: Install the Chart

Install the chart in your OpenShift project:

```bash
helm install -f openshift-config.yaml beeai \
  oci://ghcr.io/i-am-bee/beeai-platform/beeai-platform-chart/beeai-platform:latest \
  -n beeai-platform
```

### Step 6: Create OpenShift Route

Create a route to expose the BeeAI platform:

```bash
oc expose service beeai-platform-svc --port=8333
```

Or create a custom route with TLS:

`beeai-route.yaml`:
```yaml
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: beeai-platform
  namespace: beeai-platform
spec:
  host: beeai.apps.your-cluster-domain.com  # Replace with your cluster domain
  port:
    targetPort: 8333
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
  to:
    kind: Service
    name: beeai-platform-svc
    weight: 100
```

```bash
oc apply -f beeai-route.yaml
```

### Step 7: Setup LLM Configuration

After the platform becomes ready, configure your LLM provider. Get the route URL and configure the LLM:

```bash
# Get the route URL
ROUTE_URL=$(oc get route beeai-platform -o jsonpath='{.spec.host}')

# Configure LLM using curl (replace with your credentials)
curl -X PUT \
  "https://${ROUTE_URL}/api/v1/variables" \
  -u beeai-admin:my-secret-password \
  -H "Content-Type: application/json" \
  -d '{
    "env": {
        "LLM_API_BASE": "https://api.openai.com/v1",
        "LLM_API_KEY": "sk-...",
        "LLM_MODEL": "gpt-4o"
    }
  }'
```

## Use the Platform

Test that the platform is working:

```bash
# Get the route URL
ROUTE_URL=$(oc get route beeai-platform -o jsonpath='{.spec.host}')

# Configure BeeAI CLI to use the OpenShift route
export BEEAI__HOST="https://${ROUTE_URL}"

# Test the platform
beeai list
beeai run chat hi
```

## OpenShift-Specific Configuration

### Container Registry Access

If using private registries, create image pull secrets:

```bash
# Create pull secret for private registry
oc create secret docker-registry registry-secret \
  --docker-server=your-registry.com \
  --docker-username=your-username \
  --docker-password=your-password \
  --docker-email=your-email@example.com

# Link to service account
oc secrets link beeai-sa registry-secret --for=pull
```

Add to your config:

```yaml
# openshift-config.yaml
imagePullSecrets:
  - name: registry-secret
```

### Resource Quotas and Limits

Configure appropriate resource limits for OpenShift:

```yaml
# openshift-config.yaml
resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 1Gi

agent:
  resources:
    limits:
      cpu: 500m
      memory: 1Gi
    requests:
      cpu: 100m
      memory: 256Mi
```

### Network Policies

If using network policies, create appropriate rules:

`network-policy.yaml`:
```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: beeai-netpol
  namespace: beeai-platform
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: beeai-platform
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 8333
  egress:
  - {}  # Allow all egress for LLM API calls
```

```bash
oc apply -f network-policy.yaml
```

## Management Commands

### Upgrading

```bash
helm upgrade --install -f openshift-config.yaml beeai \
  oci://ghcr.io/i-am-bee/beeai-platform/beeai-platform-chart/beeai-platform:latest \
  -n beeai-platform
```

### View Current Configuration

```bash
helm get values beeai -n beeai-platform
```

### Check Deployment Status

```bash
helm status beeai -n beeai-platform
oc get pods -n beeai-platform
oc logs deployment/beeai-platform -n beeai-platform
```

### Uninstall

```bash
helm uninstall beeai -n beeai-platform
oc delete project beeai-platform
oc delete scc beeai-scc  # If no longer needed
```

## Troubleshooting

### Common OpenShift Issues

**Security Context Constraints:**
```bash
# Check if SCC is properly applied
oc describe scc beeai-scc

# Check pod security context
oc describe pod <pod-name> -n beeai-platform
```

**Route Issues:**
```bash
# Check route status
oc get routes -n beeai-platform
oc describe route beeai-platform -n beeai-platform

# Test route connectivity
curl -k https://$(oc get route beeai-platform -o jsonpath='{.spec.host}')/
```

**Image Pull Issues:**
```bash
# Check image pull secrets
oc get secrets -n beeai-platform
oc describe secret registry-secret -n beeai-platform

# Check service account
oc describe sa beeai-sa -n beeai-platform
```

**Network Connectivity:**
```bash
# Test from within the cluster
oc run test-curl --image=curlimages/curl -it --rm --restart=Never -- \
  curl -H "Authorization: Bearer your-api-key" https://api.openai.com/v1/models
```

**Resource Limits:**
```bash
# Check resource usage
oc adm top pods -n beeai-platform

# Check resource quotas
oc describe quota -n beeai-platform
```

### OpenShift Console Integration

You can also monitor the deployment through the OpenShift web console:

1. Navigate to **Workloads** → **Deployments**
2. Select the `beeai-platform` project
3. View deployment status, logs, and metrics
4. Access the application through **Networking** → **Routes**
