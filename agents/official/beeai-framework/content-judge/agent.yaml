manifestVersion: 1
name: content-judge
description: Evaluates multiple documents and agent-generated content based on correctness, depth, clarity, and relevance, selecting the highest-scoring one. It ensures optimal document quality for research, content validation, and knowledge refinement.

framework: BeeAI
license: Apache 2.0
languages: 
  - TypeScript
githubUrl: https://github.com/i-am-bee/beeai/blob/main/agents/official/beeai-framework/content-judge
avgRunTimeSeconds: 22
avgRunTokens: 1229
examples: 
  cli:
    - command: | 
        beeai run content-judge '{
          "text": "Generate a concise summary of the history of artificial intelligence.",
          "agents": [
            "gpt-researcher",
            "ollama-deep-researcher"
          ]
        }'
      name: AI Content Refinement
      description: Provide agent names that will generate the content to compare.
      output: Artificial Intelligence has evolved from early symbolic reasoning systems in the 1950s to deep learning-powered applications today, transforming industries such as healthcare, finance, and autonomous systems.
      processingSteps:
        - No pre-provided documents are available, so it queries agents for content
        - Evaluates and scores the generated responses based on correctness, clarity, and relevance
        - Returns the best summary based on the highest score
    - command: | 
        beeai run content-judge '{
          "text": "How does quantum computing impact cryptography?",
          "documents": [
            "Quantum computing poses a significant threat to classical encryption methods due to its ability to solve complex mathematical problems exponentially faster...",
            "Current cryptographic standards, such as RSA, rely on integer factorization, which quantum algorithms like Shor\\'s algorithm can efficiently break...",
            "Quantum computing will not significantly impact modern cryptography for at least another 50 years...",
          ],
          "agents": [
            "gpt-researcher", 
            "ollama-deep-researcher"
          ]
        }'
      name: Research Validation
      description: Provide existing documents to compare.
      processingSteps:
        - Queries the agents for additional insights on quantum computing and cryptography
        - Evaluates all gathered documents using the four scoring criteria
        - Assigns scores and selects the document that best aligns with the research prompt
ui: 
  type: custom
fullDescription: |
  The agent evaluates multiple documents and agent-generated content based on four key criteria - correctness, depth & coverage, clarity & structure, and relevance. It assigns a numerical score (0-1) to each document for each criterion, using a weighted average to determine the highest-scoring document. This ensures that the most accurate, comprehensive, well-structured, and relevant document is selected.

  ## How It Works

  The agent accepts two types of input:
  - **Pre-provided documents** – Static documents submitted by the user or other agents.
  - **Agent-generated content** – Content dynamically retrieved from specified agents in the system.

  The agent processes all provided text inputs and evaluates them based on the defined criteria. It then selects the document with the highest weighted score and returns it as the best choice.

  ## Input Parameters

  The agent operates based on the following input parameters:
  - **text** (string) – The research prompt or query guiding document selection.
  - **documents** (array of strings, optional) – A list of pre-provided documents for evaluation.
  - **agents** (array of strings, optional) – A list of agents to query for additional content.

  If no documents are provided, the agent relies entirely on agent-generated content.

  ## Evaluation Criteria:

  1. **Correctness (50%)** – Assesses factual accuracy, penalizing misinformation.
  2. **Depth & Coverage (10%)** – Measures how well the document explores key aspects of the topic.
  3. **Clarity & Structure (10%)** – Evaluates logical organization and readability.
  4. **Relevance (30%)** – Determines how well the document aligns with the given research prompt.

  The agent utilizes the Llama 3.1 8B model to perform structured evaluations and scoring.

  ## Use Cases
  - **Research Validation** – Ensures high-quality, well-researched content by selecting the most reliable sources.
  - **Content Refinement** – Helps refine AI-generated content by scoring and selecting the most coherent and accurate version.
  - **Document Summarization Assessment** – Evaluates multiple AI-generated summaries and chooses the most comprehensive one.
  - **Quality Assurance for AI Outputs** – Ensures AI responses in a pipeline meet accuracy and relevance requirements.

env:
- name: LLM_MODEL
  required: false
  description: "Model to use from the specified OpenAI-compatible API."
- name: LLM_API_BASE
  required: false
  description: "Base URL for OpenAI-compatible API endpoint"
- name: LLM_API_KEY
  required: false
  description: "API key for OpenAI-compatible API endpoint"
